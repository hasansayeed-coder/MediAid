{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84eabd9",
   "metadata": {},
   "source": [
    "--Imports--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae9bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from langchain.Schema import Document\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph import END\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "from langchain_community.tools.dog_search.tool import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24a1c1",
   "metadata": {},
   "source": [
    "--- Load enviroment variables and API keys---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701eeb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fcd0ca",
   "metadata": {},
   "source": [
    "--- Load $ Index medical PDF for RAG --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd250417",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('../data/medical_book.pdf')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbff3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 512 , \n",
    "    chunk_overlap = 128 , \n",
    "    seperators=[\"\\n\\n\", \". \" , \"\\n\", \" \"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419621bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e50310",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits , \n",
    "    embeddings=embeddings , \n",
    "    persist_directory=\"../medical_db/\" , \n",
    "    collection_metadata={\"hnsw:space\" : \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06325df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={'k':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c50f6",
   "metadata": {},
   "source": [
    "--- Initialize LLM ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a547a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model_name=\"openai/gpt-oss-120b\" , \n",
    "    temperature = 0.3 , \n",
    "    max_tokens = 2048\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1999b31",
   "metadata": {},
   "source": [
    "--- Initialize external tools ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = WikipediaAPIWrapper(\n",
    "    api_wrapper = WikipediaAPIWrapper(\n",
    "        top_k_results = 2 , \n",
    "        doc_content_chars_max=2000 , \n",
    "        load_all_available_meta=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f02de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckduckgo_search = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10327aa4",
   "metadata": {},
   "source": [
    "--- Define AgentState TypedDict with Success/failure flags ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict) : \n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    generation: str\n",
    "    source: str\n",
    "    search_query: Optional[str]\n",
    "    conversation_history: List[str]\n",
    "    llm_attempted: bool\n",
    "    llm_success: bool\n",
    "    rag_attempted: bool\n",
    "    rag_success: bool\n",
    "    wiki_attempted: bool\n",
    "    wiki_success: bool\n",
    "    ddg_attempted: bool\n",
    "    ddg_success: bool\n",
    "    current_tool: Optional[str]\n",
    "    retry_count: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b7a11",
   "metadata": {},
   "source": [
    "--- Memory agent (maintain short-term conversation buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MemoryAgent(state : AgentState) -> AgentState :\n",
    "    history = state.get(\"conversation_history\" , [])\n",
    "    if len(history) > 20 :\n",
    "        history = history[-20:]\n",
    "    state[\"conversation_history\"] = history\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38647649",
   "metadata": {},
   "source": [
    "--- LLM Agent : first attempt to answer ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0527466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLMAgent(state : AgentState) -> AgentState :\n",
    "\n",
    "    try : \n",
    "        ctx = \"\\n\".join(state.get(\"conversation_history\" , [] )[-10:])\n",
    "\n",
    "    except Exception : \n",
    "        state[\"llm_success\"] = False\n",
    "\n",
    "    state[\"llm_attempted\"] = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68009ba",
   "metadata": {},
   "source": [
    "--- LLM Agent : first attempt to answer ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d4e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLMAgent(state : AgentState) -> AgentState : \n",
    "\n",
    "    try : \n",
    "        ctx=\"\\n\".join(state.get(\"conversation_history\" , [])[-10 : ])\n",
    "        prompt = f\"\"\"You are a compassionate and knowledgeable medical AI assistant and doctor helping a patient. Your conversational skill should be a professional consultant with a human touch.\n",
    "\n",
    "        Patient's History : \n",
    "        {ctx}\n",
    "        Patient's Question : \n",
    "        {state[\"question\"]}\n",
    "\n",
    "\n",
    "        Respond like an experienced doctor in 2â€“3 sentences. Be clear, professional, and confident. Do not mention sources or uncertainty.\"\"\"\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        answer = response.content.strip()\n",
    "\n",
    "        if answer : \n",
    "            state[\"generation\"] = answer\n",
    "            state[\"llm_success\"] = True\n",
    "        else :\n",
    "            state[\"llm_success\"] = False\n",
    "\n",
    "    except Exception : \n",
    "        state[\"llm_success\"] = False\n",
    "\n",
    "    state[\"llm_attempted\"] = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f437a",
   "metadata": {},
   "source": [
    "--- Planner Agent : initial tool decision based on query keywords ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlannerAgent(state : AgentState) -> AgentState :\n",
    "    question = state[\"question\"]\n",
    "    medical_keywords = [\"pain\", \"fever\", \"treatment\", \"symptom\", \"diagnosis\", \"cancer\", \"disease\", \"virus\", \"bacteria\", \"infection\"]\n",
    "\n",
    "    if any(word in question for word in medical_keywords) :\n",
    "        state[\"current_tool\"] = \"llm\"\n",
    "    else : \n",
    "        state[\"current_tool\"] = \"llm\"\n",
    "\n",
    "    state[\"retry_count\"] = 0  \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8baada0",
   "metadata": {},
   "source": [
    "--- Retriever Agent (RAG) from PDF vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ae97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrieverAgent(state : AgentState) -> AgentState : \n",
    "    query = state[\"question\"]\n",
    "    context = \"\\n\".join(state.get(\"conversation_history\" , [])[-6:])\n",
    "\n",
    "    combined_query = f\"Context : {context}\\nQuestion : {query}\"\n",
    "\n",
    "    try : \n",
    "        docs == retriever.invoke(combined_query)\n",
    "\n",
    "        if docs and len(docs) > 0 : \n",
    "            state[\"documents\"] = docs\n",
    "            state[\"rag_success\"] =  True\n",
    "            state[\"conversation_history\"].append(\"AI : Retrieved documents from medical PDF database.\")\n",
    "\n",
    "        else : \n",
    "            state[\"documents\"] = []\n",
    "            state[\"rag_success\"] = False\n",
    "\n",
    "    except Exception : \n",
    "        state[\"documents\"] = []\n",
    "        state[\"rag_success\"] = False\n",
    "\n",
    "    state[\"rag_attempted\"] = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203d4f0",
   "metadata": {},
   "source": [
    "-- WikiPedia Agent Fallback ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043824d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AgentState' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mWikipediaAgent\u001b[39m(state : \u001b[43mAgentState\u001b[49m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AgentState :\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m : \n\u001b[0;32m      3\u001b[0m         conte\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AgentState' is not defined"
     ]
    }
   ],
   "source": [
    "def WikipediaAgent(state : AgentState) -> AgentState :\n",
    "    try : \n",
    "        content = wiki.run(state[\"question\"])\n",
    "\n",
    "        if content : \n",
    "            state[\"documents\"] = [Document(page_content=content)]\n",
    "            state[\"wiki_success\"] = True\n",
    "            state[\"conversation_history\"].append(\"AI : Retrieved Information from Wikipedia\")\n",
    "\n",
    "        else : \n",
    "            state[\"documents\"] = [] \n",
    "            state[\"wiki_success\"] = False\n",
    "\n",
    "    except Exception :\n",
    "        state[\"documents\"] = []\n",
    "        state[\"wiki_success\"] = False\n",
    "    \n",
    "    state[\"wiki_attempted\"] = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4894f0",
   "metadata": {},
   "source": [
    "--- DuckDuckGo Agent fallback --- -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DuckDuckGoAgent(state : AgentState) -> AgentState : \n",
    "    try : \n",
    "        content = duckduckgo_search.run(state[\"question\"])\n",
    "        if content : \n",
    "            state[\"documents\"] = [Document(page_content = content)]\n",
    "            state[\"ddg_success\"] = True\n",
    "            state[\"conversation_history\"].append(\"AI : Retrieved information from DuckDuckGo\")\n",
    "        else : \n",
    "            state[\"documents\"] = []\n",
    "            state[\"ddg_success\"] = False\n",
    "\n",
    "    except Exception : \n",
    "        state[\"documents\"] = []\n",
    "        state[\"ddg_success\"] = False\n",
    "    \n",
    "    state[\"ddg_attempted\"] = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4734f",
   "metadata": {},
   "source": [
    "--- executor Agent - Generate final answer using LLM with retrieved docs or fallback to knowledge ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cabdd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExecutorAgent(state : AgentState) -> AgentState : \n",
    "    context = state.get(\"conversation_history\" , [])\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    if state.get(\"documents\") and len(state[\"documents\"]) > 0 :\n",
    "        content = \"\\n\".join([doc.page_content for doc in state[\"documents\"]])\n",
    "        prompt = f\"\"\"You are a kind, highly experienced professional medical doctor speaking directly with a patient. Be clear, supportive and concise like human response.\n",
    "        Conversation Context:\n",
    "        {\"\".join(context[-6:])}\n",
    "\n",
    "        Patient's Question:\n",
    "        {question}\n",
    "\n",
    "        Relevant Medical Information:\n",
    "        {content}\n",
    "\n",
    "        Guidelines:\n",
    "        - Answer in 2-3 sentences.\n",
    "        - Do not mention sources.\n",
    "        - Speak like a caring human doctor.\"\"\"\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        answer = response.content.strip()\n",
    "        state[\"generation\"] = answer\n",
    "        state[\"source\"] = \"retrieved_docs\"\n",
    "        state[\"conversation_history\"].append(f\"Doctor: {answer}\")\n",
    "        return state\n",
    "    \n",
    "    if state.get(\"locals\" , False) and state.get(\"generation\") : \n",
    "        state[\"conversation_history\"].append(f\"Doctor : {state['generation']}\")\n",
    "        state[\"source\"] = \"llm_knowledge\"\n",
    "        return state\n",
    "    \n",
    "    state[\"generation\"] = \"I could not find enough information to answer\" \n",
    "    state[\"source\"] = \"none\"\n",
    "    state[\"conversation_history\"].append(state[\"generation\"])\n",
    "    return state\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8267b7e",
   "metadata": {},
   "source": [
    "--- Explanation Agent (append explanation , confidence , traceability) ----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExplanationAgent(state : AgentState) -> AgentState : \n",
    "    explanation = \"This response is generated using a combination of medical literature and AI reasoning.\"\n",
    "    state[\"conversation_history\"].append(f\"AI Explanation : {explanation}\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0aa062",
   "metadata": {},
   "source": [
    "-- Build Langgraph workflows ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99166241",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6904a4d",
   "metadata": {},
   "source": [
    "---- Add all agent nodes ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"memory\" , MemoryAgent)\n",
    "workflow.add_node(\"planner\" , PlannerAgent)\n",
    "workflow.add_node(\"llm_agent\" , LLMAgent)\n",
    "workflow.add_node(\"retriever\" , RetrieverAgent)\n",
    "workflow.add_node(\"wikipedia\" , WikipediaAgent)\n",
    "workflow.add_node(\"duckduckgo\" , DuckDuckGoAgent)\n",
    "workflow.add_node(\"executor\" , ExecutorAgent)\n",
    "workflow.add_node(\"explanation\" , ExplanationAgent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84009ab7",
   "metadata": {},
   "source": [
    "--- Set Entry Point ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89843e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_entry_point(\"memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47c0eb9",
   "metadata": {},
   "source": [
    "--- Edges and conditional routing functions for fallback chain ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(\"memory\" , \"planner\")\n",
    "workflow.add_edge(\"planner\" , \"llm_agent\")\n",
    "\n",
    "#after LLM Agent\n",
    "def route_after_llm(state  : AgentState) :\n",
    "    if state.get(\"llm_success\" , False) : \n",
    "        return \"executor\"\n",
    "    else : \n",
    "        return retriever\n",
    "    \n",
    "workflow.add_conditional_edges(\"llm_agent\" , route_after_llm , {\"executor\" : \"executor\" , \"retriever\" : \"retriever\"})\n",
    "\n",
    "#after retriever agent\n",
    "def route_after_rag(state : AgentState) : \n",
    "    if state.get(\"rag_success\" , False) : \n",
    "        return \"executor\"\n",
    "    else : \n",
    "        return \"wikipedia\"\n",
    "    \n",
    "workflow.add_conditional_edges(\"retriever\" , route_after_rag , {\"executor\" : \"executor\" , \"wikipedia\" : \"wikipedia\"})\n",
    "\n",
    "\n",
    "#After wikipedia agent\n",
    "def route_after_wiki(state : AgentState) : \n",
    "    if state.get(\"wiki_success\" , False) : \n",
    "        return \"executor\"\n",
    "    else : \n",
    "        return \"duckduckgo\"\n",
    "    \n",
    "workflow.add_conditional_edges(\"wikipedia\" , route_after_wiki , {\"executor\" : \"executor\" , \"duckduckgo\" : \"duckduckgo\"})\n",
    "\n",
    "#After Duckcuckgo agent\n",
    "def route_after_ddg(state : AgentState) -> AgentState : \n",
    "    return \"executor\"\n",
    "\n",
    "workflow.add_conditional_edges(\"duckduckgo\" , route_after_ddg , {\"executor\" : \"executor\"})\n",
    "\n",
    "#Executor to explanation then end\n",
    "workflow.add_edge(\"executor\" , 'explanation')\n",
    "workflow.add_edge('explanation' , END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac1eb5",
   "metadata": {},
   "source": [
    "--- Compile the workflow ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8efc4",
   "metadata": {},
   "source": [
    "--- Initialize conversation state ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_state : AgentState = {\n",
    "    \"question\" : \"\" , \n",
    "    \"documents\" : [] , \n",
    "    \"generation\" : \"\" , \n",
    "    \"source\" : \"\" , \n",
    "    \"search_query\" : None , \n",
    "    \"conversation_history\" : [] , \n",
    "    \"llm_attempted\" : False , \n",
    "    \"llm_success\" : False , \n",
    "    \"rag_attempted\" : False  , \n",
    "    \"rag_success\" : False , \n",
    "    \"wiki_attempted\" : False , \n",
    "    \"wiki_success\" : False , \n",
    "    \"ddg_attempted\" : False , \n",
    "    \"ddg_success\" : False , \n",
    "    \"current_tool\" : None , \n",
    "    \"retry_count\" : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93639971",
   "metadata": {},
   "source": [
    "--- Main INteraction loop ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Medical AI Assistant (Type exit to quit) ===\")\n",
    "while True : \n",
    "    query = input(\"\\nAsk your medical question : \").strip()\n",
    "\n",
    "    if query.lower() == \"exit\" : \n",
    "        conversation_state = {\n",
    "            \"question\" : \"\" , \n",
    "            \"documents\" : [] , \n",
    "            \"generation\" : \"\" , \n",
    "            \"source\" : \"\" , \n",
    "            \"search_query\" : None , \n",
    "            \"conversation_history\" : [] , \n",
    "            \"llm_attempted\" : False , \n",
    "            \"llm_success\" : False , \n",
    "            \"rag_attempted\" : False , \n",
    "            \"rag_success\" : False , \n",
    "            \"wiki_attempted\" : False , \n",
    "            \"wiki_success\" : False , \n",
    "            \"ddg_attempted\" : False , \n",
    "            \"ddg_success\" : False , \n",
    "            \"current_tool\" : None , \n",
    "            \"retry_count\" : 0 ,\n",
    "        }\n",
    "        print(\"\\n=== Consultation Ended. Conversation history cleared===\")\n",
    "        break  \n",
    "\n",
    "    #update conversation state with new question\n",
    "    conversation_state.update({\n",
    "        \"question\" : query , \n",
    "        \"documents\" : [] , \n",
    "        \"generation\" : \"\" , \n",
    "        \"source\" : \"\" , \n",
    "        \"search_query\" : None , \n",
    "        \"llm_attempted\" : False , \n",
    "        \"llm_success\" : False , \n",
    "        \"rag_attempted\" : False , \n",
    "        \"rag_success\" : False , \n",
    "        \"wiki_attempted\" : False , \n",
    "        \"wiki_success\"  : False , \n",
    "        \"ddg_attempted\" : False , \n",
    "        \"ddg_success\" : False , \n",
    "        \"current_tool\" : None , \n",
    "        \"retry_count\" : 0\n",
    "    })\n",
    "\n",
    "    #Run the langgraph workflow with current state\n",
    "    result = app.invoke(conversation_state)\n",
    "    conversation_state.update(result)\n",
    "\n",
    "    #print AI response\n",
    "    if result.get(\"generation\") : \n",
    "        print(f\"\\n[Doctor AI] {result['generation']}\")\n",
    "    else :\n",
    "        print(\"\\n[Doctor AI] Sorry , I couldnot generate an answer\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
